# -*- coding: utf-8 -*-
"""VMP with NSGA-II.ipynb

Automatically generated by Colab.

Original file is located at
	https://colab.research.google.com/drive/1_9Rjy8Ankfu-GMciQa2Ar6y52Bdy0xHE
"""

from google.colab import drive
import gurobipy as gp
import os
import sys
import time
# Import all code files
from problem_generator import generateProblem
from problem import Problem
from lp_generator import create_VMP_MOMILP_File
from pamilo_runner import PaMILORunner
from analyzer import ExperimentAnalyzer
from nsga2_classic import NSGA2Classic
from nsga2_hybrid import NSGA2Hybrid


def setup_environment():
	# Mount Google Drive
	drive.mount('/content/drive')
	# Install Gurobi 
	# !pip install gurobipy
	# Gurobi WLS License File Path
	LICENSE_PATH = '/content/drive/MyDrive/Skripsi/gurobi.lic'
	# Set Environment Variable
	os.environ["GRB_LICENSE_FILE"] = LICENSE_PATH
	# Quick License Check
	try:
		# Dummy model
		m = gp.Model("test_license")
		m.optimize()
		print("Gurobi WLS License is ACTIVE and VALIDATED!")
	except gp.GurobiError as e:
		print(f"License Error: {e}")
		print("Check if gurobi.lic is in the correct and valid path.")

	# Project Directory Path 
	BASE_PATH = '/content/drive/MyDrive/Skripsi'
	CODE_PATH = os.path.join(BASE_PATH, 'codes')
	BIN_PATH = os.path.join(BASE_PATH, 'bin')
	DATASET_DIR = os.path.join(BASE_PATH, 'dataset')
	RESULTS_DIR = os.path.join(BASE_PATH, 'results')
	PAMILO_EXE = os.path.join(BIN_PATH, 'PaMILO') # Nama file binary Linux

	# Add CODE_PATH if it doesn't exist
	if CODE_PATH not in sys.path:
		sys.path.append(CODE_PATH)
	"""Menyiapkan folder dan izin eksekusi."""
	print("--- Setting Up Environment ---")

	# Make new directories for experiment results (if they don't exist)
	os.makedirs(DATASET_DIR, exist_ok=True)
	os.makedirs(os.path.join(RESULTS_DIR, 'lp_files'), exist_ok=True)
	os.makedirs(os.path.join(RESULTS_DIR, 'pamilo_sols'), exist_ok=True)
	os.makedirs(os.path.join(RESULTS_DIR, 'nsga_results'), exist_ok=True)

	# Grant permision to PaMILO CLI executable
	if os.path.exists(PAMILO_EXE):
		os.chmod(PAMILO_EXE, 0o755) # chmod +x
		print(f"[Setup] Permission to execute is granted to {PAMILO_EXE}")
	else:
		print(f"[Setup] WARNING: PaMILO binary is not found at {PAMILO_EXE}")

def run_experiment_pipeline():
	setup_environment()

	# Tool
	pamilo_runner = PaMILORunner(PAMILO_EXE)
	analyzer = ExperimentAnalyzer()

	# --- TAHAP 1: GENERATE PROBLEM (JIKA KOSONG) ---
	# Cek apakah folder dataset kosong
	if not os.listdir(DATASET_DIR):
		print("\n--- Generating Datasets ---")
		# Generate 5 Small & 5 Large (Sesuai rencana skripsi)
		for i in range(1, 6):
			generateProblem(os.path.join(DATASET_DIR, f"small_{i}.json"), 'small', seed_value=i)
			generateProblem(os.path.join(DATASET_DIR, f"large_{i}.json"), 'large', seed_value=100+i)
	else:
		print("\n[Info] Dataset sudah ada. Melewati tahap generate.")

	# --- TAHAP 2: LOOP EKSPERIMEN PER PROBLEM ---
	# Ambil semua file json, urutkan agar rapi
	problem_files = sorted([f for f in os.listdir(DATASET_DIR) if f.endswith(".json")])

	for p_file in problem_files:
		scenario_name = p_file.replace(".json", "")
		full_path = os.path.join(DATASET_DIR, p_file)

		print(f"\n{'='*60}")
		print(f"PROCESSING SCENARIO: {scenario_name}")
		print(f"{'='*60}")

		# 1. Load Problem
		problem = Problem()
		problem.loadFromFile(full_path)

		# ---------------------------------------------------------
		# JALUR A: SOLUSI EKSAK (PaMILO) - HANYA UNTUK SMALL
		# ---------------------------------------------------------
		if 'small' in scenario_name:
			lp_path = os.path.join(RESULTS_DIR, "lp_files", f"{scenario_name}.lp")
			pamilo_out_path = os.path.join(RESULTS_DIR, "pamilo_sols", f"{scenario_name}_sol.json")

			# Generate LP jika belum ada
			if not os.path.exists(lp_path):
				create_VMP_MOMILP_File(problem, lp_path)

			# Run PaMILO jika belum ada solusinya
			if not os.path.exists(pamilo_out_path):
				print(f"[PaMILO] Solving {scenario_name}...")
				success = pamilo_runner.solve(lp_path, pamilo_out_path, timeout_sec=3600) # 1 Jam
			else:
				print("[PaMILO] Solution found. Loading...")
				success = True

			# Load ke Analyzer
			if success:
				analyzer.loadPamiloReference(pamilo_out_path)
		else:
			print("[PaMILO] Skipping exact solver for Large scale instance.")

		# ---------------------------------------------------------
		# JALUR B: NSGA-II (30 RUNS)
		# ---------------------------------------------------------
		TOTAL_RUNS = 30

		# Reset results di analyzer untuk problem baru (opsional, tergantung desain analyzer)
		# Jika analyzer didesain menampung SEMUA data eksperimen sekaligus, jangan di-reset.
		# Asumsi: Analyzer menampung kumulatif.

		print(f"[NSGA-II] Starting {TOTAL_RUNS} runs...")

		for run_id in range(TOTAL_RUNS):
			# Seed unik: 1000 + (id_scenario * 100) + run_id
			# Agar seed beda tiap problem dan tiap run
			base_seed = int(''.join(filter(str.isdigit, scenario_name))) if any(char.isdigit() for char in scenario_name) else 0
			seed = 1000 + (base_seed * 100) + run_id

			# -- Run Classic --
			# print(f"  > Run {run_id+1} Classic...", end="\r")
			algo_classic = NSGA2Classic(
				problem,
				populationSize=100,
				maxGeneration=100, # Ubah sesuai kebutuhan
				crossoverProbability=0.9,
				mutationProbability=0.1
			)
			# Set seed (pastikan ada method ini di kelas NSGA2 atau set global random)
			# algo_classic.set_seed(seed)
			algo_classic.run()
			analyzer.addResult('Classic', f"{scenario_name}_r{run_id}", algo_classic.population)

			# -- Run Hybrid --
			# print(f"  > Run {run_id+1} Hybrid... ", end="\r")
			algo_hybrid = NSGA2Hybrid(
				problem,
				populationSize=100,
				maxGeneration=100,
				crossoverProbability=0.9,
				mutationProbability=0.1
			)
			# algo_hybrid.set_seed(seed)
			algo_hybrid.run()
			analyzer.addResult('Hybrid', f"{scenario_name}_r{run_id}", algo_hybrid.population)

		print(f"\n[NSGA-II] Completed {TOTAL_RUNS} runs for {scenario_name}.")

	# --- TAHAP 3: FINALISASI & REPORT ---
	print("\n--- Calculating Final Metrics ---")
	final_stats = analyzer.computeMetrics()

	# Cetak ringkasan singkat
	print("\n=== SUMMARY RESULTS ===")
	for algo in ['Classic', 'Hybrid']:
		if algo in final_stats and final_stats[algo]:
			avg_hv = sum(x['hv'] for x in final_stats[algo]) / len(final_stats[algo])
			avg_igd = sum(x['igd_plus'] for x in final_stats[algo]) / len(final_stats[algo])
			print(f"[{algo}] Avg Hypervolume: {avg_hv:.4f} | Avg IGD+: {avg_igd:.4f}")

	# (Opsional) Simpan stats object ke file pickle/json untuk dianalisis nanti
	# import pickle
	# with open(os.path.join(RESULTS_DIR, 'final_stats.pkl'), 'wb') as f:
	#	 pickle.dump(final_stats, f)

	print("\n[DONE] Pipeline finished successfully.")

if __name__ == "__main__":
	# Mount Drive otomatis jika dijalankan di Colab
	try:
		drive.mount('/content/drive')
	except:
		pass # Abaikan jika dijalankan lokal atau sudah mounted

	run_experiment_pipeline()